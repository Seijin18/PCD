# Projeto K-Means 1D - CUDA GPU

ImplementaÃ§Ã£o do algoritmo K-Means 1D com paralelizaÃ§Ã£o em GPU usando CUDA (Entrega 2).

## ğŸ¯ Objetivo

Comparar o desempenho da implementaÃ§Ã£o do K-Means 1D entre:
- **CPU (Sequencial):** VersÃ£o otimizada em C para linha de base
- **GPU (CUDA):** VersÃ£o paralelizada usando NVIDIA CUDA

## ğŸ“Š CaracterÃ­sticas

### VersÃ£o Sequencial (CPU)
- **Arquivo:** `kmeans_1d_seq.c`
- **Compilador:** GCC/Clang
- **OtimizaÃ§Ãµes:** -O3, cache-friendly allocation
- **Tempo de mediÃ§Ã£o:** clock() de alta precisÃ£o

### VersÃ£o CUDA (GPU)
- **Arquivo:** `kmeans_1d_cuda.cu`
- **Compilador:** NVCC (NVIDIA CUDA Compiler)
- **Kernels:**
  - `kernel_assignment`: AtribuiÃ§Ã£o paralela de pontos (1 thread por ponto)
  - `kernel_update_partial`: AcumulaÃ§Ã£o paralela de somas (operaÃ§Ãµes atÃ´micas)
  - `kernel_update_centroids`: CÃ¡lculo paralelo de novos centrÃ³ides
  - `kernel_reduce_sse`: ReduÃ§Ã£o paralela do SSE em shared memory
- **Tempo de mediÃ§Ã£o:** cudaEventElapsedTime() para precisÃ£o GPU

## ğŸ“ Estrutura

```
Cuda/
â”œâ”€â”€ kmeans_1d_seq.c              # ImplementaÃ§Ã£o sequencial (CPU)
â”œâ”€â”€ kmeans_1d_cuda.cu            # ImplementaÃ§Ã£o CUDA (GPU)
â”œâ”€â”€ run_cuda_experiments.ps1     # Script de compilaÃ§Ã£o e execuÃ§Ã£o
â”œâ”€â”€ compare_cuda_results.py      # ValidaÃ§Ã£o de corretude
â”œâ”€â”€ README.md                    # Este arquivo
â””â”€â”€ dados.csv                    # Dados de teste (gerado)
    centroides_iniciais.csv      # CentrÃ³ides iniciais (gerado)
```

## ğŸš€ Como Usar

### PrÃ©-requisitos

```powershell
# Windows
# - GCC (MinGW)
# - CUDA Toolkit 11.0+ (inclui NVCC)
# - Python 3.x com NumPy

# Verificar CUDA
nvidia-smi

# Adicionar CUDA ao PATH (se necessÃ¡rio)
$env:PATH += ";C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\bin"
```

### 1. ExecuÃ§Ã£o AutomÃ¡tica (Recomendado)

```powershell
cd Cuda
.\run_cuda_experiments.ps1
```

Este script:
- âœ“ Gera/usa dados de teste
- âœ“ Compila versÃ£o CPU (GCC)
- âœ“ Compila versÃ£o CUDA (NVCC)
- âœ“ Executa ambas as versÃµes 3 vezes
- âœ“ Calcula speedup
- âœ“ Valida resultados

### 2. CompilaÃ§Ã£o Manual

#### VersÃ£o Sequencial (CPU)
```bash
gcc -O3 -std=c99 kmeans_1d_seq.c -o kmeans_1d_seq.exe -lm
```

#### VersÃ£o CUDA (GPU)
```bash
# Detectar compute capability da GPU
nvidia-smi

# Compilar (exemplo para GeForce GTX 1660 Ti - sm_75)
nvcc -O3 -arch=sm_75 kmeans_1d_cuda.cu -o kmeans_1d_cuda.exe

# Outras opÃ§Ãµes de -arch:
# sm_50 = Maxwell (GTX 750, 960, 970, 980, etc)
# sm_60 = Pascal (GTX 1060, 1070, 1080, etc)
# sm_61 = Pascal (GTX Titan X, 1080 Ti, etc)
# sm_70 = Volta (Titan V, Tesla V100, etc)
# sm_75 = Turing (RTX 2060, 2070, 2080, GTX 1660, 1660 Ti, etc)
# sm_80 = Ampere (RTX 3060, 3070, 3080, 3090, etc)
# sm_86 = Ampere (RTX 3050, etc)
# sm_90 = Ada (RTX 4080, 4090, etc)
```

### 3. Executar Individualmente

#### VersÃ£o CPU
```bash
.\kmeans_1d_seq.exe dados.csv centroides_iniciais.csv 20
```

#### VersÃ£o GPU
```bash
.\kmeans_1d_cuda.exe dados.csv centroides_iniciais.csv 20
```

### 4. Validar Resultados

```bash
python compare_cuda_results.py
```

Verifica:
- EquivalÃªncia de atribuiÃ§Ãµes
- EquivalÃªncia de centrÃ³ides
- EquivalÃªncia de SSE

## ğŸ“– Algoritmo Detalhado

### Assignment Step (GPU)

```cuda
__global__ void kernel_assignment(double *data, int N, double *centroids, int K,
                                   int *assignments, double *sse_array)
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= N) return;
    
    // Cada thread processa um ponto
    double point = data[i];
    double min_dist = INFINITY;
    int best_cluster = 0;
    
    // Encontrar centrÃ³ide mais prÃ³ximo
    for (int k = 0; k < K; k++) {
        double diff = point - centroids[k];
        double dist = diff * diff;
        if (dist < min_dist) {
            min_dist = dist;
            best_cluster = k;
        }
    }
    
    assignments[i] = best_cluster;
    sse_array[i] = min_dist;  // Usado para reduÃ§Ã£o de SSE
}
```

**ParalelizaÃ§Ã£o:**
- Grid: âŒˆN / 256âŒ‰ blocos de 256 threads
- Cada thread processa 1 ponto
- Complexidade: O(N Ã— K)

### Update Step (GPU)

#### Passo 1: Acumular Somas (Paralelo)
```cuda
__global__ void kernel_update_partial(int *assignments, double *data, int N, int K,
                                       double *sum_global, int *count_global)
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= N) return;
    
    int cluster = assignments[i];
    atomicAdd(&sum_global[cluster], data[i]);     // OperaÃ§Ã£o atÃ´mica
    atomicAdd(&count_global[cluster], 1);
}
```

#### Passo 2: Calcular Novos CentrÃ³ides (Paralelo)
```cuda
__global__ void kernel_update_centroids(double *centroids, double *sum_global,
                                         int *count_global, int K, double *data, int N)
{
    int k = blockIdx.x * blockDim.x + threadIdx.x;
    if (k >= K) return;
    
    if (count_global[k] > 0) {
        centroids[k] = sum_global[k] / count_global[k];
    } else {
        centroids[k] = data[0];
    }
}
```

**ParalelizaÃ§Ã£o:**
- Kernel 1: âŒˆN / 256âŒ‰ blocos Ã— 256 threads (acumular)
- Kernel 2: âŒˆK / 256âŒ‰ blocos Ã— 256 threads (calcular)
- Usa operaÃ§Ãµes atÃ´micas para thread-safety

### ReduÃ§Ã£o de SSE (GPU)

```cuda
__global__ void kernel_reduce_sse(double *sse_array, int N, double *sse_result)
{
    extern __shared__ double sdata[];
    
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    sdata[threadIdx.x] = (idx < N) ? sse_array[idx] : 0.0;
    __syncthreads();
    
    // ReduÃ§Ã£o em shared memory (tree reduction)
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (threadIdx.x < s) {
            sdata[threadIdx.x] += sdata[threadIdx.x + s];
        }
        __syncthreads();
    }
    
    if (threadIdx.x == 0) {
        sse_result[blockIdx.x] = sdata[0];
    }
}
```

## ğŸ“Š Esperado de Desempenho

### GPU: NVIDIA GeForce GTX 1660 Ti

| N | K | CPU | GPU | Speedup |
|---|---|-----|-----|---------|
| 10K | 20 | ~1ms | ~2ms | 0.5x |
| 100K | 20 | ~10ms | ~5ms | 2x |
| 1M | 20 | ~100ms | ~20ms | 5x |
| 5M | 20 | ~500ms | ~60ms | 8x |

**ObservaÃ§Ãµes:**
- Speedup Ã© baixo para problemas pequenos (overhead CUDA domina)
- Speedup cresce com N (GPU explora paralelismo)
- TransferÃªncia PCI-E Ã© sobrecarga importante

## ğŸ” ValidaÃ§Ã£o de Corretude

### AtribuiÃ§Ãµes
- Devem ser 100% idÃªnticas (ou muito similares se pontos sÃ£o equidistantes)
- Script verifica primeiras 10.000 atribuiÃ§Ãµes

### CentrÃ³ides
- Devem ser numericamente equivalentes (tolerÃ¢ncia: 1e-5)
- Pode haver pequenas diferenÃ§as por ordem de operaÃ§Ãµes em paralelo

### SSE (Sum of Squared Errors)
- Calculado a partir de atribuiÃ§Ãµes + centrÃ³ides
- Deve ter diferenÃ§a relativa < 0.1%

## ğŸ“ Arquivos de SaÃ­da

### CPU
- `assign_seq.csv`: AtribuiÃ§Ãµes (N linhas, 1 inteiro por linha)
- `centroids_seq.csv`: CentrÃ³ides finais (K linhas, 1 double por linha)

### GPU
- `assign_cuda.csv`: AtribuiÃ§Ãµes (N linhas)
- `centroids_cuda.csv`: CentrÃ³ides finais (K linhas)

## ğŸ”§ Troubleshooting

### ERRO: "nvcc: command not found"
```powershell
# Adicionar CUDA ao PATH
$env:PATH += ";C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\bin"
```

### ERRO: "Device does not support this compute capability"
```bash
# Descobrir compute capability da GPU
nvidia-smi

# Usar o valor correto com -arch. Exemplo:
# Para GTX 1660 Ti (sm_75)
nvcc -O3 -arch=sm_75 kmeans_1d_cuda.cu -o kmeans_1d_cuda.exe
```

### GPU muito lenta (mais lenta que CPU)
- Normal para N < 100K
- Overhead CUDA domina para problemas pequenos
- Aumentar N para observar speedup

### SaÃ­da CUDA vazia/erros
```bash
# Verificar disponibilidade de GPU
nvidia-smi

# Testar com programa CUDA simples
cat > test_cuda.cu << 'EOF'
#include <stdio.h>
__global__ void kernel() { printf("GPU funciona!\n"); }
int main() { kernel<<<1,1>>>(); cudaDeviceSynchronize(); }
EOF
nvcc test_cuda.cu -o test_cuda
./test_cuda
```

## ğŸ“š ReferÃªncias

- [NVIDIA CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
- [K-Means Clustering](https://en.wikipedia.org/wiki/K-means_clustering)
- [Atomic Operations in CUDA](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#atomic-functions)
- [Parallel Reduction](https://docs.nvidia.com/cuda/samples/1_Utilities/reduction/)

## ğŸ“‹ Notas

- VersÃ£o CUDA usa `cudaEventElapsedTime()` para mediÃ§Ã£o com precisÃ£o de GPU
- VersÃ£o CPU usa `get_time_ms()` que detecta Windows/Linux automaticamente
- Ambas garantem resultados determinÃ­sticos com mesma seed
- TransferÃªncia PCI-E (CPU â†” GPU) Ã© considerada no tempo total

## ğŸ‘¨â€ğŸ’» Autor

ImplementaÃ§Ã£o para disciplina de ProgramaÃ§Ã£o Concorrente e DistribuÃ­da
