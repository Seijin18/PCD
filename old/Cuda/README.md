# Projeto K-Means 1D - CUDA GPU Otimizado

ImplementaÃ§Ã£o otimizada do algoritmo K-Means 1D com paralelizaÃ§Ã£o em GPU usando CUDA.

## ğŸ¯ Objetivo

Comparar o desempenho da implementaÃ§Ã£o do K-Means 1D entre:
- **CPU (Sequencial):** VersÃ£o otimizada em C para linha de base
- **GPU (CUDA):** VersÃ£o paralelizada com otimizaÃ§Ãµes avanÃ§adas

## ğŸ“Š CaracterÃ­sticas

### VersÃ£o Sequencial (CPU)
- **Arquivo:** `kmeans_1d_seq.c`
- **Compilador:** GCC/MSVC
- **OtimizaÃ§Ãµes:** -O3, cache-friendly allocation
- **Tempo de mediÃ§Ã£o:** clock() de alta precisÃ£o

### VersÃ£o CUDA (GPU) - Otimizada
- **Arquivo:** `kmeans_1d_cuda_optimized.cu`
- **Compilador:** NVCC (NVIDIA CUDA Compiler)
- **OtimizaÃ§Ãµes Implementadas:**
  - **MemÃ³ria Constante:** CentrÃ³ides em cache constante (acesso rÃ¡pido)
  - **ReduÃ§Ã£o por Blocos:** AgregaÃ§Ã£o eficiente usando shared memory
  - **Block Size AutomÃ¡tico:** Teste e seleÃ§Ã£o automÃ¡tica do tamanho Ã³timo
  - **SSE no Host:** CÃ¡lculo de SSE na CPU para reduzir overhead
- **Kernels:**
  - `kernel_assignment_optimized`: AtribuiÃ§Ã£o com memÃ³ria constante
  - `kernel_update_reduction`: AgregaÃ§Ã£o eficiente por blocos
- **Tempo de mediÃ§Ã£o:** cudaEvent com precisÃ£o de microssegundos

## ğŸ“ Estrutura do Projeto

```
Cuda/
â”œâ”€â”€ data/                              # ğŸ“¥ Dados de entrada
â”‚   â”œâ”€â”€ dados.csv                      # Dataset (100,000 pontos)
â”‚   â””â”€â”€ centroides_iniciais.csv        # CentrÃ³ides iniciais (K=20)
â”‚
â”œâ”€â”€ results/                           # ğŸ“Š Resultados e mÃ©tricas
â”‚   â”œâ”€â”€ assign_cuda.csv               # AtribuiÃ§Ãµes GPU
â”‚   â”œâ”€â”€ assign_seq.csv                # AtribuiÃ§Ãµes CPU
â”‚   â”œâ”€â”€ centroids_cuda.csv            # CentrÃ³ides finais GPU
â”‚   â”œâ”€â”€ centroids_seq.csv             # CentrÃ³ides finais CPU
â”‚   â”œâ”€â”€ block_size_test.csv           # Teste de tamanhos de bloco
â”‚   â”œâ”€â”€ metrics_cuda.csv              # MÃ©tricas estruturadas
â”‚   â”œâ”€â”€ metrics_cuda.txt              # MÃ©tricas legÃ­veis
â”‚   â”œâ”€â”€ validation_cuda.txt           # ValidaÃ§Ã£o GPU vs CPU
â”‚   â””â”€â”€ comparacao_seq_vs_cuda.txt    # ComparaÃ§Ã£o detalhada
â”‚
â”œâ”€â”€ graphs/                            # ğŸ“ˆ GrÃ¡ficos (gerados)
â”‚   â”œâ”€â”€ block_size_analysis.png
â”‚   â”œâ”€â”€ throughput_analysis.png
â”‚   â”œâ”€â”€ timing_breakdown.png
â”‚   â””â”€â”€ performance_summary.png
â”‚
â”œâ”€â”€ kmeans_1d_cuda_optimized.cu       # ImplementaÃ§Ã£o CUDA otimizada
â”œâ”€â”€ kmeans_1d_seq.c                   # ImplementaÃ§Ã£o sequencial
â”œâ”€â”€ generate_performance_graphs.py     # GeraÃ§Ã£o de grÃ¡ficos
â”œâ”€â”€ generate_comparison.ps1            # GeraÃ§Ã£o de relatÃ³rio
â”œâ”€â”€ build_and_analyze_cuda.ps1        # Build automÃ¡tico completo
â””â”€â”€ README.md                          # Este arquivo
```

## ğŸš€ Como Usar

### PrÃ©-requisitos

```powershell
# Windows
# - CUDA Toolkit 11.0+ (inclui NVCC)
# - Visual Studio 2019+ com C++ Build Tools
# - Python 3.8+ com pandas, matplotlib, numpy (opcional, para grÃ¡ficos)

# Verificar CUDA e GPU
nvidia-smi

# Verificar NVCC
nvcc --version
```

### 1. ExecuÃ§Ã£o AutomÃ¡tica Completa (Recomendado)

```powershell
cd Cuda
.\build_and_analyze_cuda.ps1
```

Este script realiza todo o workflow:
- âœ“ Detecta automaticamente compute capability da GPU
- âœ“ Compila versÃ£o CUDA otimizada
- âœ“ Executa com teste automÃ¡tico de block sizes (32, 64, 128, 256, 512)
- âœ“ Gera mÃ©tricas de desempenho (CSV e TXT)
- âœ“ Valida resultados contra versÃ£o sequencial
- âœ“ Gera grÃ¡ficos de anÃ¡lise (se Python disponÃ­vel)
- âœ“ Salva todos os resultados em `results/`

### 2. CompilaÃ§Ã£o Manual

#### VersÃ£o Sequencial (CPU)
```bash
# Windows (MSVC)
cl /O2 kmeans_1d_seq.c /Fe:kmeans_1d_seq.exe

# Windows (GCC/MinGW)
gcc -O3 -std=c99 kmeans_1d_seq.c -o kmeans_1d_seq.exe
```

#### VersÃ£o CUDA (GPU)
```bash
# Detectar compute capability
nvidia-smi --query-gpu=compute_cap --format=csv,noheader

# Compilar (exemplo para GTX 1660 Ti - sm_75)
nvcc -O3 -arch=sm_75 kmeans_1d_cuda_optimized.cu -o kmeans_1d_cuda_opt.exe
```

**Compute Capabilities comuns:**
- sm_75 = Turing (RTX 2060/2070/2080, GTX 1660/1660 Ti)
- sm_80 = Ampere (RTX 3060/3070/3080/3090)
- sm_86 = Ampere (RTX 3050, RTX 30 Mobile)
- sm_89 = Ada Lovelace (RTX 4060/4070)
- sm_90 = Ada Lovelace (RTX 4080/4090)

### 3. Executar Individualmente

#### VersÃ£o CPU
```powershell
.\kmeans_1d_seq.exe data/dados.csv data/centroides_iniciais.csv 20 100 1e-6
```

#### VersÃ£o GPU
```powershell
.\kmeans_1d_cuda_opt.exe data/dados.csv data/centroides_iniciais.csv 20 100 1e-6
```

**ParÃ¢metros:**
- `data/dados.csv` - Arquivo de entrada com pontos
- `data/centroides_iniciais.csv` - CentrÃ³ides iniciais
- `20` - NÃºmero de clusters (K)
- `100` - NÃºmero mÃ¡ximo de iteraÃ§Ãµes
- `1e-6` - Epsilon de convergÃªncia

### 4. Gerar GrÃ¡ficos de Desempenho

```powershell
python generate_performance_graphs.py .
```

Gera 4 grÃ¡ficos profissionais:
- **block_size_analysis.png** - AnÃ¡lise de tamanhos de bloco
- **throughput_analysis.png** - Throughput e eficiÃªncia
- **timing_breakdown.png** - DecomposiÃ§Ã£o de tempo
- **performance_summary.png** - Resumo geral (6 painÃ©is)

### 5. Gerar RelatÃ³rio de ComparaÃ§Ã£o

```powershell
.\generate_comparison.ps1 -seq_time 208.0 -cuda_time 93.789
```

Cria `results/comparacao_seq_vs_cuda.txt` com anÃ¡lise detalhada.

## ğŸ“– Algoritmo e OtimizaÃ§Ãµes

### Assignment Step (GPU) - Com MemÃ³ria Constante

```cuda
__constant__ double constant_centroids[MAX_K];

__global__ void kernel_assignment_optimized(double *data, int N, int K,
                                             int *assignments, double *sse_array) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= N) return;
    
    double point = data[i];
    double min_dist = 1e308;
    int best_cluster = 0;
    
    // Usar centrÃ³ides da memÃ³ria constante (cache rÃ¡pido)
    for (int k = 0; k < K; k++) {
        double diff = point - constant_centroids[k];
        double dist = diff * diff;
        if (dist < min_dist) {
            min_dist = dist;
            best_cluster = k;
        }
    }
    
    assignments[i] = best_cluster;
    sse_array[i] = min_dist;
}
```

**OtimizaÃ§Ãµes:**
- âœ“ MemÃ³ria constante para centrÃ³ides (acesso em cache L1)
- âœ“ Sem divergÃªncia de warp (todas as threads executam mesmo cÃ³digo)
- âœ“ Complexidade: O(N Ã— K) totalmente paralela

### Update Step (GPU) - ReduÃ§Ã£o por Blocos

```cuda
__global__ void kernel_update_reduction(int *assignments, double *data, int N, int K,
                                         double *block_sums, int *block_counts) {
    extern __shared__ char shared_memory[];
    
    double *shared_sums = (double *)shared_memory;
    int *shared_counts = (int *)&shared_memory[K * sizeof(double)];
    
    // Inicializar shared memory
    for (int k = threadIdx.x; k < K; k += blockDim.x) {
        shared_sums[k] = 0.0;
        shared_counts[k] = 0;
    }
    __syncthreads();
    
    // Acumular em shared memory
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < N) {
        int cluster = assignments[i];
        atomicAdd(&shared_sums[cluster], data[i]);
        atomicAdd(&shared_counts[cluster], 1);
    }
    __syncthreads();
    
    // Escrever resultados do bloco para memÃ³ria global
    for (int k = threadIdx.x; k < K; k += blockDim.x) {
        if (shared_sums[k] != 0.0 || shared_counts[k] != 0) {
            atomicAdd(&block_sums[k], shared_sums[k]);
            atomicAdd(&block_counts[k], shared_counts[k]);
        }
    }
}
```

**OtimizaÃ§Ãµes:**
- âœ“ Shared memory reduz acessos Ã  memÃ³ria global
- âœ“ OperaÃ§Ãµes atÃ´micas apenas dentro do bloco (muito mais rÃ¡pido)
- âœ“ Reduz contenÃ§Ã£o de memÃ³ria global significativamente

### Block Size AutomÃ¡tico

O cÃ³digo testa automaticamente mÃºltiplos tamanhos de bloco:
- **32, 64, 128, 256, 512 threads**
- Seleciona o melhor baseado em tempo de execuÃ§Ã£o real
- Resultados salvos em `results/block_size_test.csv`

## ğŸ“Š Resultados de Desempenho

### ConfiguraÃ§Ã£o Testada
- **Dataset:** 100,000 pontos
- **Clusters (K):** 20
- **IteraÃ§Ãµes:** 100
- **GPU:** NVIDIA GeForce GTX 1660 Ti (1536 CUDA cores, Compute 7.5)
- **CPU:** Intel/AMD (sequencial)
### MÃ©tricas de Desempenho

| MÃ©trica | Sequencial (CPU) | CUDA (GPU) | Melhoria |
|---------|------------------|------------|----------|
| **Tempo Total** | 208.0 ms | 93.8 ms | **2.22x** |
| **Tempo/IteraÃ§Ã£o** | 2.08 ms | 0.938 ms | 2.22x |
| **Throughput** | 48.08 M pts/s | 107.15 M pts/s | 2.23x |
| **Overhead H2D** | - | 0.177 ms | 0.2% |
| **Tempo Kernels** | - | 93.329 ms | 99.5% |
| **Overhead D2H** | - | 0.283 ms | 0.3% |

### ValidaÃ§Ã£o de Corretude

| VerificaÃ§Ã£o | Resultado |
|-------------|-----------|
| **Match AtribuiÃ§Ãµes** | 100.00% (0 diferenÃ§as) |
| **DiferenÃ§a SSE** | < 1e-10 (praticamente zero) |
| **DiferenÃ§a CentrÃ³ides** | 3.96e-11 (mÃ¡xima) |
| **Status** | âœ… PASSOU |

### Block Size Ã“timo

| Block Size | Tempo/IteraÃ§Ã£o |
|------------|----------------|
| 32 threads | 0.126 ms |
| **64 threads** | **0.111 ms âœ“ MELHOR** |
| 128 threads | 0.111 ms |
| 256 threads | 0.114 ms |
| 512 threads | 0.123 ms |

**ConfiguraÃ§Ã£o Ã“tima:**
- Block size: **64 threads**
- Grid size: 1563 blocos
- OcupaÃ§Ã£o: Ã“tima para Turing (sm_75)

## ğŸ“ Arquivos de SaÃ­da

### DiretÃ³rio `results/`

#### MÃ©tricas e ValidaÃ§Ã£o
- **metrics_cuda.csv** - MÃ©tricas estruturadas (CSV)
- **metrics_cuda.txt** - MÃ©tricas legÃ­veis (texto)
- **block_size_test.csv** - Resultados de teste de block sizes
- **validation_cuda.txt** - ValidaÃ§Ã£o GPU vs CPU
- **comparacao_seq_vs_cuda.txt** - ComparaÃ§Ã£o detalhada completa

#### Resultados do Algoritmo
- **assign_cuda.csv** / **assign_seq.csv** - AtribuiÃ§Ãµes (N linhas)
- **centroids_cuda.csv** / **centroids_seq.csv** - CentrÃ³ides finais (K linhas)

### DiretÃ³rio `graphs/`

- **block_size_analysis.png** - Linha: tempo vs block size
- **throughput_analysis.png** - Barra + pizza: throughput e distribuiÃ§Ã£o
- **timing_breakdown.png** - Barras: decomposiÃ§Ã£o de tempo H2D/Kernels/D2H
- **performance_summary.png** - Dashboard 6 painÃ©is: visÃ£o geral completa

## ğŸ”§ Troubleshooting

### ERRO: "nvcc: command not found" ou "Cannot find compiler 'cl.exe'"

```powershell
# 1. Adicionar MSVC ao PATH (necessÃ¡rio no Windows)
$msvcPath = "C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.44.35207\bin\Hostx64\x64"
$env:PATH = "$msvcPath;" + $env:PATH

# 2. Adicionar CUDA ao PATH
$env:PATH += ";C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\bin"

# 3. Verificar
nvcc --version
cl.exe
```

### ERRO: "Device does not support this compute capability"

```powershell
# Descobrir compute capability da GPU
nvidia-smi --query-gpu=compute_cap --format=csv,noheader

# Usar o valor correto. Exemplo para GTX 1660 Ti (7.5):
nvcc -O3 -arch=sm_75 kmeans_1d_cuda_optimized.cu -o kmeans_1d_cuda_opt.exe
```

### GPU mais lenta que CPU

**Causas comuns:**
- Normal para N < 50K (overhead CUDA domina)
- TransferÃªncias PCI-E sÃ£o gargalo em problemas pequenos
- **SoluÃ§Ã£o:** Aumentar N para 500K-1M para ver speedup real

### Arquivos nÃ£o encontrados

```powershell
# Verificar estrutura de diretÃ³rios
Get-ChildItem data/
Get-ChildItem results/

# Executar com caminhos corretos
.\kmeans_1d_cuda_opt.exe data/dados.csv data/centroides_iniciais.csv 20 100 1e-6
```

### Python nÃ£o gera grÃ¡ficos

```powershell
# Instalar dependÃªncias
pip install pandas matplotlib numpy

# Executar em ambiente virtual (recomendado)
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install pandas matplotlib numpy
python generate_performance_graphs.py .
```

## ğŸ’¡ Dicas de OtimizaÃ§Ã£o

### Para Aumentar Speedup

1. **Aumentar tamanho do problema:**
   ```powershell
   # Gerar dataset maior (1M pontos)
   python generate_data.py 1000000 20
   ```

2. **Aumentar nÃºmero de clusters (K):**
   - K maior = mais trabalho computacional
   - Melhor aproveitamento da GPU

3. **Usar problema multidimensional:**
   - K-Means 2D/3D tem muito mais operaÃ§Ãµes
   - GPU se beneficia mais de problemas complexos

### Para Reduzir Overhead

- Minimizar transferÃªncias H2D/D2H
- Usar streams CUDA para sobreposiÃ§Ã£o
- Pinned memory para transferÃªncias mais rÃ¡pidas
- Processar mÃºltiplos datasets em batch

## ğŸ“š ReferÃªncias

- [NVIDIA CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
- [CUDA Constant Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#device-memory-accesses)
- [Shared Memory in CUDA](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#shared-memory)
- [Atomic Operations in CUDA](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#atomic-functions)
- [K-Means Clustering Algorithm](https://en.wikipedia.org/wiki/K-means_clustering)

## ğŸ“‹ Notas TÃ©cnicas

### ImplementaÃ§Ã£o
- VersÃ£o CUDA usa `cudaEvent` para mediÃ§Ã£o precisa de tempo na GPU
- VersÃ£o CPU usa `clock()` com detecÃ§Ã£o automÃ¡tica Windows/Linux
- Ambas garantem resultados determinÃ­sticos com mesma seed
- SSE calculado no host (CPU) para reduzir overhead de kernel

### OtimizaÃ§Ãµes Aplicadas
1. **MemÃ³ria Constante:** Cache L1 de 64KB, broadcast para threads do warp
2. **Shared Memory:** ReduÃ§Ã£o de acessos Ã  memÃ³ria global (100x mais rÃ¡pida)
3. **Block Size Ã“timo:** Testado automaticamente para hardware especÃ­fico
4. **Coalesced Memory Access:** Acesso sequencial otimizado aos dados

### LimitaÃ§Ãµes
- Problema 1D tem baixa intensidade aritmÃ©tica (poucos FLOPs por byte)
- Overhead de lanÃ§amento de kernel Ã© significativo para N pequeno
- Speedup ideal requer N > 500K para saturar GPU moderna

## ğŸ¯ ConclusÃµes

### Desempenho AlcanÃ§ado
- âœ… **Speedup de 2.22x** para 100K pontos
- âœ… **Overhead mÃ­nimo** de comunicaÃ§Ã£o (0.5%)
- âœ… **100% de corretude** validada
- âœ… **Block size otimizado** automaticamente

### RecomendaÃ§Ãµes
- Para **problemas pequenos** (N < 50K): CPU Ã© mais eficiente
- Para **problemas mÃ©dios** (50K < N < 500K): GPU oferece speedup moderado (2-3x)
- Para **problemas grandes** (N > 500K): GPU oferece speedup significativo (5-10x)
- Para **mÃ¡ximo desempenho**: Usar K-Means 2D/3D com mais operaÃ§Ãµes por ponto

## ğŸ‘¨â€ğŸ’» Autor

ImplementaÃ§Ã£o para disciplina de ProgramaÃ§Ã£o Concorrente e DistribuÃ­da

---

**VersÃ£o:** 2.0 (Otimizada)  
**Data:** Novembro 2025  
**GPU Testada:** NVIDIA GeForce GTX 1660 Ti (Compute 7.5)
